{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = pd.read_csv('iot-datasets/train.csv')\n",
    "test_file = pd.read_csv('iot-datasets/test.csv')\n",
    "severity_type = pd.read_csv('iot-datasets/severity_type.csv')\n",
    "event_type = pd.read_csv('iot-datasets/event_type.csv')\n",
    "log_feature = pd.read_csv('iot-datasets/log_feature.csv')\n",
    "resource_type = pd.read_csv('iot-datasets/resource_type.csv')\n",
    "volume = log_feature[['id','volume']]\n",
    "log_feature = log_feature.drop('volume', axis=1)\n",
    "\n",
    "location = train_file[['id','location']]\n",
    "train_file = train_file.drop('location',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"severity_type shape:{severity_type.shape}\" )\n",
    "print(f\"event_type shape:{event_type.shape}\" )\n",
    "print(f\"log_feature shape:{log_feature.shape}\" )\n",
    "print(f\"resource_type shape:{resource_type.shape}\" )\n",
    "print(f\"volume shape:{volume.shape}\" )\n",
    "print(f\"location shape:{location.shape}\" )\n",
    "print(f\"train shape:{train_file.shape}\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity_type.drop_duplicates(keep='first')\n",
    "event_type.drop_duplicates(keep='first')\n",
    "resource_type.drop_duplicates(keep='first')\n",
    "log_feature.drop_duplicates(keep='first')\n",
    "volume.drop_duplicates(keep='first')\n",
    "\n",
    "print(f\"severity_type shape:{severity_type.shape}\" )\n",
    "print(f\"event_type shape:{event_type.shape}\" )\n",
    "print(f\"log_feature shape:{log_feature.shape}\" )\n",
    "print(f\"resource_type shape:{resource_type.shape}\" )\n",
    "print(f\"volume shape:{volume.shape}\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity_type = severity_type.pivot_table(index='id', columns='severity_type', aggfunc='size')\n",
    "severity_type.reset_index(inplace=True)\n",
    "\n",
    "event_type = event_type.pivot_table(index='id', columns='event_type', aggfunc='size')\n",
    "event_type.reset_index(inplace=True)\n",
    "\n",
    "resource_type = resource_type.pivot_table(index='id', columns='resource_type', aggfunc='size')\n",
    "resource_type.reset_index(inplace=True)\n",
    "\n",
    "log_feature = log_feature.pivot_table(index='id', columns='log_feature', aggfunc='size')\n",
    "log_feature.reset_index(inplace=True)\n",
    "\n",
    "location = location.pivot_table(index='id', columns='location', aggfunc='size')\n",
    "location.reset_index(inplace=True)\n",
    "\n",
    "prefix = 'Volume '\n",
    "volume['volume'] = volume['volume'].apply(lambda x: prefix + str(x))\n",
    "volume = volume.pivot_table(index='id', columns='volume', aggfunc='size')\n",
    "volume.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(train_file,severity_type,on='id',how='left')\n",
    "df = pd.merge(df,event_type,on='id',how='left')\n",
    "df = pd.merge(df,resource_type,on='id',how='left')\n",
    "df = pd.merge(df,log_feature,on='id',how='left')\n",
    "df = pd.merge(df,volume,on='id',how='left')\n",
    "df_with_location = pd.merge(df,location,on='id',how='left')\n",
    "df_without_location = df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_with_location\n",
    "# df = df_without_location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0, inplace=True)\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "for column in df.columns:\n",
    "    if column != 'id' or column!='fault_severity':\n",
    "        df[column] = label_encoder.fit_transform(df[column])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['fault_severity']\n",
    "X = df.drop(['fault_severity','id'], axis=1)\n",
    "print(\"Number of examples: \" + str(X.shape[0]))\n",
    "print(\"\\nNumber of Features:\" + str(X.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, y_train,y_test =  train_test_split(X,y, test_size=0.33,random_state=1234)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_y_pred = lr_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "lr_accuracy = accuracy_score(y_test, lr_y_pred)\n",
    "print('Accuracy score of Logistic regression: ' + str(lr_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "knn_y_pred = knn_model.predict(X_test)\n",
    "knn_accuracy = accuracy_score(y_test, knn_y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy score of KNN: ' + str(knn_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'max_depth':[4,8],'min_samples_leaf':[25,50]}\n",
    "print('Running grid search')\n",
    "dt_regressor = DecisionTreeClassifier()\n",
    "dt_grid = GridSearchCV(dt_regressor,param_grid,cv=3, scoring='neg_root_mean_squared_error')\n",
    "dt_grid_search = dt_grid.fit(X_train,y_train)\n",
    "print('finished grid search')\n",
    "\n",
    "\n",
    "#get the best parameters for decision tree\n",
    "dt_best_params= dt_grid_search.best_params_\n",
    "print(f\"best parameters for decision tree model: {dt_best_params}\")\n",
    "dt_model = DecisionTreeClassifier(max_depth=dt_best_params['max_depth'], min_samples_leaf=dt_best_params['min_samples_leaf'])\n",
    "dt_model.fit(X_train, y_train)\n",
    "y_dt_pred =dt_model.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, y_dt_pred)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy of Decision Tree:\", dt_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'max_depth':[4,8,10,20,32],'n_estimators':[25,50,100,200,300]}\n",
    "print('Running grid search')\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_grid = GridSearchCV(rf_model,param_grid,cv=3, scoring='neg_root_mean_squared_error')\n",
    "rf_grid_search = rf_grid.fit(X_train,y_train)\n",
    "print('finished grid search')\n",
    "\n",
    "rf_best_params= rf_grid_search.best_params_\n",
    "print(f\"best parameters for rf model: {rf_best_params}\")\n",
    "rf_model = RandomForestClassifier(max_depth=rf_best_params['max_depth'],n_estimators = rf_best_params['n_estimators'])\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_rf_pred=rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, y_rf_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy of Random Forest:\", rf_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_grid = {'max_depth':[4,8,10],'n_estimators':[25,50,100,200,300]}\n",
    "print('Running grid search')\n",
    "gbdt_model = GradientBoostingClassifier()\n",
    "GBDT_grid = GridSearchCV(gbdt_model,param_grid,cv=3, scoring='neg_root_mean_squared_error')\n",
    "GBDT_grid_search = GBDT_grid.fit(X_train,y_train)\n",
    "print('finished grid search')\n",
    "\n",
    "\n",
    "GBDT_best_params= GBDT_grid_search.best_params_\n",
    "print(f\"best parameters for GBDT model: {GBDT_best_params}\")\n",
    "\n",
    "gbdt_model = GradientBoostingClassifier(max_depth=GBDT_best_params['max_depth'], n_estimators=GBDT_best_params['n_estimators'])\n",
    "gbdt_model.fit(X_train,y_train)\n",
    "y_gbdt_pred =  gbdt_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbdt_accuracy = accuracy_score(y_test, y_gbdt_pred)\n",
    "print(\"Accuracy:\", gbdt_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "nb_y_pred = nb_model.predict(X_test)\n",
    "nb_accuracy = accuracy_score(y_test, nb_y_pred)\n",
    "print(\"Accuracy:\", nb_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model_linear = svm.SVC(kernel='rbf', gamma=0.5, C=0.1).fit(X_train, y_train)\n",
    "svm_y_pred = svm_model_linear.predict(X_test)\n",
    "svm_accuracy = accuracy_score(y_test, svm_y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy of SVM:\", svm_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = gbdt_model.feature_importances_\n",
    "df_features = pd.DataFrame({'name':X_train.columns.values, 'imp':feature_imp})\n",
    "df_sorted =df_features.sort_values(by=['imp'],  ascending=False)\n",
    "top_five = df_sorted.iloc[:6]['name'].tolist()\n",
    "print('Top five features: {0}'.format(top_five))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.bar(np.arange(6), sorted(rf_model.feature_importances_, reverse=True)[:6], width = 0.35)\n",
    "ax.set_xticks(np.arange(6))\n",
    "ax.set_xticklabels(top_five, rotation = 90)\n",
    "\n",
    "for i, v in enumerate(sorted(rf_model.feature_importances_, reverse=True)[:6]):\n",
    "    plt.text(i, v, f\"{v:.2f}\", ha='center', va='bottom')\n",
    "\n",
    "plt.title('Feature importance from GBDT')\n",
    "ax.set_ylabel('Normalized importance')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_results = [lr_accuracy, knn_accuracy, dt_accuracy, rf_accuracy, gbdt_accuracy, nb_accuracy, svm_accuracy]\n",
    "labels = ['LR', 'KNN', 'DT', 'RF', 'GBDT', 'NB', 'SVM']\n",
    "label_accuracy_pairs = list(zip(labels, accuracy_results))\n",
    "sorted_label_accuracy_pairs = sorted(label_accuracy_pairs, key=lambda x: x[1], reverse=True)\n",
    "accuracy_results = [pair[1] for pair in sorted_label_accuracy_pairs]\n",
    "\n",
    "labels = [pair[0] for pair in sorted_label_accuracy_pairs]\n",
    "\n",
    "rg= np.arange(7)\n",
    "width = 0.35\n",
    "plt.bar(rg, accuracy_results, width, label=\"Accuracy\")\n",
    "plt.xticks(rg + width/2, labels)\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim([0,1])\n",
    "\n",
    "for i, v in enumerate(accuracy_results):\n",
    "    plt.text(i, v, f\"{v:.2f}\", ha='center', va='bottom')\n",
    "\n",
    "\n",
    "plt.title('Model Performance')\n",
    "plt.legend(loc='upper left', ncol=2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
